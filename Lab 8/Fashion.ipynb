{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5mIU02iUZxe"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euj-Q4viUZx6"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmfA9dsrUZx7"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORtS414nUZx8",
        "outputId": "d5394a6d-4d6e-4b22-d202-a84c5dfce1a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJVZyPU3UZyC"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXefwUzJUZyD"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "_sM-Zrt_UZyE",
        "outputId": "98450e2a-958f-430b-e3c7-9ab80505ccd7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYMdozQ-UZyH"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr0EiV2mUZyI"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDWaz1hrUZyJ"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Yag0BZqFUZyK"
      },
      "outputs": [],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "num_classes = 10\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)\n",
        "\n",
        "X_train_norm = X_train.astype('float32') / 255.0\n",
        "X_test_norm = X_test.astype('float32') / 255.0\n",
        "\n",
        "X_train_norm = X_train_norm.reshape((X_train_norm.shape[0], -1))\n",
        "X_test_norm = X_test_norm.reshape((X_test_norm.shape[0], -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heMCHbxLUZyL"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "56dWLpn4UZyM"
      },
      "outputs": [],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(10, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKlw29XUZyO"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J0qt8RjUZyP",
        "outputId": "60112b46-cd6f-456f-9057-9ab7d922c868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.0657 - accuracy: 0.6360\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5460 - accuracy: 0.8107\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4897 - accuracy: 0.8314\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4621 - accuracy: 0.8390\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4462 - accuracy: 0.8443\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4345 - accuracy: 0.8483\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4247 - accuracy: 0.8514\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4144 - accuracy: 0.8556\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4098 - accuracy: 0.8566\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4075 - accuracy: 0.8565\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4001 - accuracy: 0.8586\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.3943 - accuracy: 0.8609\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.3919 - accuracy: 0.8623\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.3894 - accuracy: 0.8616\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.3866 - accuracy: 0.8627\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3824 - accuracy: 0.8648\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.3794 - accuracy: 0.8654\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.3782 - accuracy: 0.8661\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.3751 - accuracy: 0.8664\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3715 - accuracy: 0.8683\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3716 - accuracy: 0.8680\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3685 - accuracy: 0.8702\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3666 - accuracy: 0.8685\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3659 - accuracy: 0.8706\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3658 - accuracy: 0.8703\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3633 - accuracy: 0.8702\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3611 - accuracy: 0.8710\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3615 - accuracy: 0.8711\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3601 - accuracy: 0.8711\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3584 - accuracy: 0.8715\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3569 - accuracy: 0.8725\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3558 - accuracy: 0.8720\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3574 - accuracy: 0.8721\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3541 - accuracy: 0.8730\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3530 - accuracy: 0.8741\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3520 - accuracy: 0.8736\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3500 - accuracy: 0.8743\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3506 - accuracy: 0.8745\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3506 - accuracy: 0.8744\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3485 - accuracy: 0.8758\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3473 - accuracy: 0.8755\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3472 - accuracy: 0.8768\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3466 - accuracy: 0.8749\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3463 - accuracy: 0.8755\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3456 - accuracy: 0.8760\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3441 - accuracy: 0.8765\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3436 - accuracy: 0.8764\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3421 - accuracy: 0.8763\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3424 - accuracy: 0.8770\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3412 - accuracy: 0.8773\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3418 - accuracy: 0.8765\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3410 - accuracy: 0.8777\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3407 - accuracy: 0.8778\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3398 - accuracy: 0.8776\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3395 - accuracy: 0.8779\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3376 - accuracy: 0.8787\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3372 - accuracy: 0.8787\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3375 - accuracy: 0.8787\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3379 - accuracy: 0.8780\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3362 - accuracy: 0.8805\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3358 - accuracy: 0.8787\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3344 - accuracy: 0.8802\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3349 - accuracy: 0.8789\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3339 - accuracy: 0.8804\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3343 - accuracy: 0.8791\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3344 - accuracy: 0.8786\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3338 - accuracy: 0.8805\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3330 - accuracy: 0.8796\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3320 - accuracy: 0.8800\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3322 - accuracy: 0.8803\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3301 - accuracy: 0.8806\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3309 - accuracy: 0.8809\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3315 - accuracy: 0.8810\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3311 - accuracy: 0.8811\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3302 - accuracy: 0.8810\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3309 - accuracy: 0.8798\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3296 - accuracy: 0.8817\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3282 - accuracy: 0.8820\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3286 - accuracy: 0.8814\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3286 - accuracy: 0.8812\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3281 - accuracy: 0.8810\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3277 - accuracy: 0.8823\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3264 - accuracy: 0.8821\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3269 - accuracy: 0.8819\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3263 - accuracy: 0.8828\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3262 - accuracy: 0.8831\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3272 - accuracy: 0.8821\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3268 - accuracy: 0.8823\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3247 - accuracy: 0.8830\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3247 - accuracy: 0.8831\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3252 - accuracy: 0.8835\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3240 - accuracy: 0.8828\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3252 - accuracy: 0.8823\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3245 - accuracy: 0.8830\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3249 - accuracy: 0.8822\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3243 - accuracy: 0.8823\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3246 - accuracy: 0.8827\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3237 - accuracy: 0.8826\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3229 - accuracy: 0.8837\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3229 - accuracy: 0.8840\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d18f4d180>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdq95hgPUZyR"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty9hDA8CUZyS",
        "outputId": "0d8d2b61-b70c-49ae-ce51-c3569170e7e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.885283350944519\n",
            "accuracy on test with NN: 0.8457000255584717\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aZB_q7YUZyU"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYJzhqLxUZyU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNro_L8QUZyW"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-DM2khkqUZyX"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr4cTCFtUZyY",
        "outputId": "92ec2f83-2741-4176-d9a6-b13faac58075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on train 0.8573\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on train', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10OCu-T2UZyZ"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSGJ_3bDUZya"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}