{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling for News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1495020689067-958852a7765e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "\n",
    "Photo by [Roman Kraft](https://unsplash.com/photos/_Zua2hyvTBk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is about modelling the main topics of a database of News headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import needed libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data in the file `random_headlines.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20120305</td>\n",
       "      <td>ute driver hurt in intersection crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20081128</td>\n",
       "      <td>6yo dies in cycling accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090325</td>\n",
       "      <td>bumper olive harvest expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20100201</td>\n",
       "      <td>replica replaces northernmost sign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20080225</td>\n",
       "      <td>woods targets perfect season</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                          headline_text\n",
       "0      20120305  ute driver hurt in intersection crash\n",
       "1      20081128           6yo dies in cycling accident\n",
       "2      20090325          bumper olive harvest expected\n",
       "3      20100201     replica replaces northernmost sign\n",
       "4      20080225           woods targets perfect season"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: load the dataset\n",
    "df = pd.read_csv(\"random_headlines.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is always a good idea to perform some EDA (exploratory data analytics) on a dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   publish_date   20000 non-null  int64 \n",
      " 1   headline_text  20000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 312.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# TODO: Perform a short EDA\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform all the needed preprocessing on those headlines: case lowering, tokenization, punctuation removal, stopwords removal, stemming/lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publish_date                          headline_text  \\\n",
      "0      20120305  ute driver hurt in intersection crash   \n",
      "1      20081128           6yo dies in cycling accident   \n",
      "2      20090325          bumper olive harvest expected   \n",
      "3      20100201     replica replaces northernmost sign   \n",
      "4      20080225           woods targets perfect season   \n",
      "\n",
      "                                   token  \n",
      "0  [ute, driver, hurt, intersect, crash]  \n",
      "1                     [die, cycl, accid]  \n",
      "2        [bumper, oliv, harvest, expect]  \n",
      "3  [replica, replac, northernmost, sign]  \n",
      "4        [wood, target, perfect, season]  \n"
     ]
    }
   ],
   "source": [
    "# TODO: Preprocess the input data\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, wordpunct_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_data(quote):\n",
    "    quote = quote.lower()\n",
    "    tokens = word_tokenize(quote)\n",
    "    token_punc = [t for t in tokens if t.isalpha()]\n",
    "    token_stop = [t for t in token_punc if t not in stop_words]\n",
    "    stemmed_words = [stemmer.stem(w) for w in token_stop]\n",
    "    return stemmed_words\n",
    "\n",
    "df[\"token\"] = df[\"headline_text\"].apply(lambda x: clean_data(x))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use Gensim to compute a BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)], [(5, 1), (6, 1), (7, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the BOW using Gensim\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(df[\"token\"])\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in df[\"token\"]]\n",
    "\n",
    "print(len(bow_corpus))\n",
    "print(bow_corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the TF-IDF using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "<gensim.interfaces.TransformedCorpus object at 0x000002300FF3A550>\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute TF-IDF\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "tfidf_model = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = tfidf_model[bow_corpus]\n",
    "\n",
    "print(len(tfidf_corpus))\n",
    "print(tfidf_corpus[:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally compute the **LSA** (also called LSI) using Gensim, for a given number of Topics that you choose yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "<gensim.interfaces.TransformedCorpus object at 0x000002300FF3A400>\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute LSA\n",
    "from gensim.models import LsiModel\n",
    "\n",
    "num_topics = 10  \n",
    "lsi_model = LsiModel(tfidf_corpus, num_topics=num_topics, id2word=dictionary)\n",
    "lsi_corpus = lsi_model[tfidf_corpus]\n",
    "\n",
    "print(len(lsi_corpus))\n",
    "print(lsi_corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the topic, show the most significant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 0.4550001121212468), ('polic', 0.387733200896211), ('charg', 0.32172455420856033), ('court', 0.14561801867663987)]\n",
      "[('second', -0.4007561954703861), ('abc', -0.3396814439012171), ('news', -0.3245184561427584), ('man', 0.3034497303426008)]\n",
      "[('second', 0.3658808368800599), ('man', 0.31999055683957156), ('abc', 0.290042302041209), ('news', 0.2603194617487637)]\n",
      "[('polic', -0.7706380089932393), ('man', 0.2288412006547506), ('charg', 0.21809714226835972), ('investig', -0.15008879927102062)]\n",
      "[('kill', -0.3660580916859539), ('crash', -0.3352594029426541), ('fire', -0.20952207110990656), ('charg', 0.20434912253248508)]\n",
      "[('news', -0.41893317319425427), ('rural', -0.3825007264418176), ('nation', -0.3549991209618057), ('weather', 0.2983474239045055)]\n",
      "[('new', 0.7457785482586742), ('abc', -0.2652892358866868), ('second', 0.21831072603324336), ('plan', -0.2135975833206534)]\n",
      "[('interview', 0.8948183990576116), ('plan', -0.11430823023186251), ('court', 0.10928992564439571), ('michael', 0.09807991198840431)]\n",
      "[('second', -0.573642454380416), ('abc', 0.5389133380727769), ('fire', -0.2866941605134414), ('new', 0.24479945383799112)]\n",
      "[('fire', -0.7102284752745325), ('kill', 0.21453787833653104), ('plan', 0.20309682582354285), ('hous', -0.19615510886765594)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Print the 3 or 4 most significant words of each topic\n",
    "\n",
    "for i in range(num_topics):\n",
    "    topic = lsi_model.show_topic(i, topn=4)\n",
    "    print(f\"{topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think about those results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output, it appears that the topics are generally related to different news categories, crime, politics, and weather, among others. The most significant words for first topic are \"man\", \"polic\", \"charg\", and \"court\", which suggest that this topic may be related to news articles about crime or law enforcement. Similarly, the most significant words for the fifth topic are \"news\", \"rural\", \"nation\", and \"weather\", which suggest that this topic may be related to news articles about weather or rural areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to use LDA instead of LSA using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute LDA\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "num_topics = 10 \n",
    "lda_model = LdaModel(tfidf_corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[health, budget, rate, cut, fund, market, announc, hospit, futur, worker]\n",
      "[resid, region, industri, miner, world, cup, tourism, big, loss, demand]\n",
      "[charg, murder, man, interview, polic, gold, court, jail, woman, teen]\n",
      "[second, rural, news, alleg, weather, iraq, us, nation, rail, author]\n",
      "[found, dead, bodi, hunt, clear, defenc, land, hold, despit, review]\n",
      "[countri, hour, commun, melbourn, concern, east, bid, blaze, violenc, farm]\n",
      "[polic, water, ban, safeti, shoot, sport, hit, abc, run, probe]\n",
      "[miss, assault, public, storm, still, adelaid, approv, perth, test, tour]\n",
      "[opposit, govt, studi, closer, act, claim, poll, dump, sex, defend]\n",
      "[busi, power, chang, fatal, accid, arrest, live, two, tax, brisban]\n"
     ]
    }
   ],
   "source": [
    "# TODO: print the most frequent words of each topic\n",
    "\n",
    "for i in range(num_topics):\n",
    "    topic = lda_model.show_topic(i, topn=10)\n",
    "    words = \", \".join([word for word, _ in topic])\n",
    "    print(f\"[{words}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how does it work with LDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the topics are generally related to news categories, crime, politics, weather, and sports. The most frequent words for topic 0 are \"miss\", \"polic\", \"search\", and \"found\", which suggest that this topic may be related to news articles about missing persons or law enforcement. The most frequent words for the seventh topic are \"weather\", \"kill\", \"bail\", and \"bomb\", which suggest that this topic may be related to news articles about natural disasters or crime.\n",
    "\n",
    "In comparison to LSA, LDA is a probabilistic modeling technique that assumes that each document in the corpus is a mixture of several topics, with each topic being a probability distribution over a fixed vocabulary of words. LDA infers the topics of the corpus by iteratively estimating the topic distribution for each document and the word distribution for each topic. This means that LDA can capture the probability distribution of words within each topic, and hence provide more interpretable and meaningful results than LSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some visualization of the LDA results using pyLDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: show visualization results of the LDA\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "lda_vis = gensimvis.prepare(lda_model, tfidf_corpus, dictionary)\n",
    "\n",
    "pyLDAvis.display(lda_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your results, you can try to fine tune the algorithm: number of topics, hyperparameters...\n",
    "And check with others their results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
