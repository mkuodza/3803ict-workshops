{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we master the preprocessing, let's make our first Bag Of Words (BOW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse our dataset of Coldplay songs to make a BOW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the first step is to import some libraries. So import *nltk* as well as all the libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK and all the needed libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load now the dataset in *coldplay.csv* using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Link</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Another's Arms</td>\n",
       "      <td>/c/coldplay/anothers+arms_21079526.html</td>\n",
       "      <td>Late night watching tv  \\nUsed to be you here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Bigger Stronger</td>\n",
       "      <td>/c/coldplay/bigger+stronger_20032648.html</td>\n",
       "      <td>I want to be bigger stronger drive a faster ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>/c/coldplay/daylight_20032625.html</td>\n",
       "      <td>To my surprise, and my delight  \\nI saw sunris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Everglow</td>\n",
       "      <td>/c/coldplay/everglow_21104546.html</td>\n",
       "      <td>Oh, they say people come  \\nThey say people go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Every Teardrop Is A Waterfall</td>\n",
       "      <td>/c/coldplay/every+teardrop+is+a+waterfall_2091...</td>\n",
       "      <td>I turn the music up, I got my records on  \\nI ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Artist                           Song  \\\n",
       "0  Coldplay                 Another's Arms   \n",
       "1  Coldplay                Bigger Stronger   \n",
       "2  Coldplay                       Daylight   \n",
       "3  Coldplay                       Everglow   \n",
       "4  Coldplay  Every Teardrop Is A Waterfall   \n",
       "\n",
       "                                                Link  \\\n",
       "0            /c/coldplay/anothers+arms_21079526.html   \n",
       "1          /c/coldplay/bigger+stronger_20032648.html   \n",
       "2                 /c/coldplay/daylight_20032625.html   \n",
       "3                 /c/coldplay/everglow_21104546.html   \n",
       "4  /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  Late night watching tv  \\nUsed to be you here ...  \n",
       "1  I want to be bigger stronger drive a faster ca...  \n",
       "2  To my surprise, and my delight  \\nI saw sunris...  \n",
       "3  Oh, they say people come  \\nThey say people go...  \n",
       "4  I turn the music up, I got my records on  \\nI ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset in coldplay.csv\n",
    "df = pd.read_csv('coldplay.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already know this dataset, but you can check it again if you want to refresh your memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Artist  120 non-null    object\n",
      " 1   Song    120 non-null    object\n",
      " 2   Link    120 non-null    object\n",
      " 3   Lyrics  120 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.9+ KB\n",
      "None\n",
      "          Artist            Song                                     Link  \\\n",
      "count        120             120                                      120   \n",
      "unique         1             120                                      120   \n",
      "top     Coldplay  Another's Arms  /c/coldplay/anothers+arms_21079526.html   \n",
      "freq         120               1                                        1   \n",
      "\n",
      "                                                   Lyrics  \n",
      "count                                                 120  \n",
      "unique                                                120  \n",
      "top     Late night watching tv  \\nUsed to be you here ...  \n",
      "freq                                                    1  \n",
      "Artist    0\n",
      "Song      0\n",
      "Link      0\n",
      "Lyrics    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Explore the data\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the *CountVectorizer* of scikit-learn, make a BOW of all the lyrics of Coldplay, and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 793)\t3\n",
      "  (0, 967)\t3\n",
      "  (0, 1683)\t3\n",
      "  (0, 1616)\t3\n",
      "  (0, 1646)\t3\n",
      "  (0, 1571)\t9\n",
      "  (0, 96)\t3\n",
      "  (0, 1770)\t4\n",
      "  (0, 673)\t3\n",
      "  (0, 127)\t3\n",
      "  (0, 892)\t15\n",
      "  (0, 1772)\t4\n",
      "  (0, 63)\t18\n",
      "  (0, 66)\t2\n",
      "  (0, 158)\t4\n",
      "  (0, 996)\t2\n",
      "  (0, 948)\t2\n",
      "  (0, 1704)\t4\n",
      "  (0, 1523)\t4\n",
      "  (0, 1745)\t2\n",
      "  (0, 895)\t2\n",
      "  (0, 980)\t2\n",
      "  (0, 44)\t16\n",
      "  (0, 1032)\t2\n",
      "  (0, 757)\t3\n",
      "  :\t:\n",
      "  (119, 1647)\t2\n",
      "  (119, 1601)\t3\n",
      "  (119, 102)\t2\n",
      "  (119, 988)\t6\n",
      "  (119, 408)\t1\n",
      "  (119, 1735)\t1\n",
      "  (119, 632)\t1\n",
      "  (119, 1189)\t2\n",
      "  (119, 1698)\t1\n",
      "  (119, 893)\t6\n",
      "  (119, 133)\t1\n",
      "  (119, 33)\t1\n",
      "  (119, 834)\t1\n",
      "  (119, 1661)\t6\n",
      "  (119, 1408)\t1\n",
      "  (119, 403)\t6\n",
      "  (119, 669)\t1\n",
      "  (119, 325)\t3\n",
      "  (119, 719)\t1\n",
      "  (119, 375)\t1\n",
      "  (119, 841)\t1\n",
      "  (119, 1693)\t5\n",
      "  (119, 519)\t1\n",
      "  (119, 1081)\t1\n",
      "  (119, 516)\t1\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute a BOW\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "coldplay_df = df[df['Artist'] == 'Coldplay']\n",
    "\n",
    "bow = vectorizer.fit_transform(coldplay_df['Lyrics'])\n",
    "\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the BOW matrix, we would like to have a new dataframe having the BOW for each song, and as columns the corresponding words (just as we did in the lecture at the end).\n",
    "\n",
    "So that at the end we would end up with a dataframe containing something like the following (120 raws for 120 songs, and as many columns as words):\n",
    "\n",
    "| | ah | adventure | ... | yeah \n",
    "|---|---|---|---|---| \n",
    "| 0 | 0 | 1 | ... | 4 |\n",
    "| 1 | 8 | 0 | ... | 2 |\n",
    "|...|...|...|...|...|\n",
    "| 119 | 5 | 0 | ... | 8 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10  2000  2gether  76543  aaaaaah  aaaaah  aaaah  about  above  achin  \\\n",
      "0     0     0        0      0        0       0      0      0      0      0   \n",
      "1     0     0        0      0        0       0      0      0      0      0   \n",
      "2     0     0        0      0        0       0      0      0      0      0   \n",
      "3     0     0        0      0        0       0      0      0      0      0   \n",
      "4     0     0        0      0        0       0      0      0      0      0   \n",
      "..   ..   ...      ...    ...      ...     ...    ...    ...    ...    ...   \n",
      "115   0     0        0      0        0       0      0      1      2      0   \n",
      "116   0     0        0      0        0       0      0      0      0      0   \n",
      "117   0     0        1      0        0       0      0      0      0      0   \n",
      "118   0     0        0      0        0       0      0      0      0      0   \n",
      "119   0     0        0      0        0       0      0      0      0      0   \n",
      "\n",
      "     ...  yellow  yes  yesterday  yet  you  young  your  yours  yourself  \\\n",
      "0    ...       0    0          0    0    4      0     4      0         2   \n",
      "1    ...       0    0          0    0    0      0     0      0         0   \n",
      "2    ...       0    0          0    0    0      0     0      0         0   \n",
      "3    ...       0    0          0    0   16      0     0      0         0   \n",
      "4    ...       0    0          0    0    2      0     0      0         0   \n",
      "..   ...     ...  ...        ...  ...  ...    ...   ...    ...       ...   \n",
      "115  ...       0    0          0    0    5      0     3      0         0   \n",
      "116  ...       0    0          0    0    9      0     0      0         0   \n",
      "117  ...       0    0          0    0    7      0     4      0         0   \n",
      "118  ...       0    0          0    0   16      0     1      0         0   \n",
      "119  ...       0    0          0    0    5      0     0      0         0   \n",
      "\n",
      "     yuletide  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "..        ...  \n",
      "115         0  \n",
      "116         0  \n",
      "117         0  \n",
      "118         0  \n",
      "119         0  \n",
      "\n",
      "[120 rows x 1776 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a new dataframe containing the BOW outputs and the corresponding words as columns. And print it\n",
    "\n",
    "bow = vectorizer.fit_transform(coldplay_df['Lyrics'])\n",
    "\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "bow_df = pd.DataFrame(bow.toarray(), columns=words)\n",
    "\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well as you see we're still having some issue, we have some tokens that are not words, like '10' or '2000'.\n",
    "\n",
    "To get rid of that, we could use directly regular expressions within the function. Another solution would be to make preprocessing before using the function *CountVectorizer*.\n",
    "\n",
    "For the moment, we won't pay attention to this issue. But if you are curious and have time, you can find on google how to remove those words using the *CountVectorizer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to see what are the most used words by Coldplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_bow = bow_df.sum()\n",
    "sum_bow.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is the most used word? Are you surprised?\n",
    "\n",
    "Now make a sort in order to show the 10 most used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most used words by Coldplay are:\n",
      " you    994\n",
      "the    777\n",
      "and    650\n",
      "to     481\n",
      "it     458\n",
      "oh     334\n",
      "in     318\n",
      "me     314\n",
      "my     288\n",
      "on     285\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: print the 10 most used word by Coldplay\n",
    "\n",
    "sorted_bow = bow_df.sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"The 10 most used words by Coldplay are:\\n\", sorted_bow[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is! You know the Coldplay lyrics more than the singers now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
